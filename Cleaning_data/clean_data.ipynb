{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy \n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import *\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedData():\n",
    "    def __init__(self):\n",
    "        self.tappy_data = self.create_tappy_dict()\n",
    "        self.patient_data = self.create_patient_dict()\n",
    "    def get_tappy_data(self):\n",
    "        return self.tappy_data\n",
    "    \n",
    "    def get_patient_data(self):\n",
    "        return self.patient_data\n",
    "        \n",
    "    # Create a dictionry of all patient data\n",
    "    def create_patient_dict(self):\n",
    "        archived_users = os.listdir('../Archived users')\n",
    "        all_patients_demographic_data = {}\n",
    "        for i in archived_users:\n",
    "            all_patients_demographic_data[i[5:15]] = self.clean_demographic_data(i)\n",
    "        \n",
    "        return all_patients_demographic_data\n",
    "\n",
    "    # Create a dictionary of all tappy data\n",
    "    def create_tappy_dict(self):\n",
    "        all_patient_tappy_data = {}\n",
    "        tappy_data = os.listdir('../Tappy Data')\n",
    "        for i in tappy_data:\n",
    "            all_patient_tappy_data[tuple([i[0:10],i[12:16]])] = self.clean_tappy_data(i)\n",
    "        \n",
    "        return all_patient_tappy_data\n",
    "    def clean_demographic_data(self, file_name):\n",
    "        first= open('../Archived users/' + file_name, 'r')\n",
    "        lines = first.readlines()\n",
    "        dictionary = {}\n",
    "        for i in lines:\n",
    "            value = i[i.index(':')+1:].strip(' ')\n",
    "            key = i[:i.index(':')+1].strip(' ')\n",
    "            if value[0] == '\\n' or value[0] == '-':\n",
    "                dictionary[key] = None\n",
    "            else:\n",
    "                dictionary[key] = value.strip('\\n')\n",
    "        return dictionary\n",
    "    def clean_tappy_data(self, file_name):\n",
    "        second= open('../Tappy Data/' + file_name)\n",
    "        lines = second.readlines()\n",
    "        dictionary = {}\n",
    "        mean_flight_time = 0\n",
    "        mean_latency_time = 0\n",
    "        mean_hold_time = 0\n",
    "        num_data_points = 0\n",
    "        for i in lines:\n",
    "            vals = i.split('\\t')\n",
    "            \n",
    "            if (len(vals[4]) == 6 and len(vals[6]) == 6 and len(vals[7]) == 6):\n",
    "                mean_flight_time += float(vals[4])\n",
    "                mean_latency_time += float(vals[6])\n",
    "                mean_hold_time += float(vals[7])\n",
    "                num_data_points += 1\n",
    "            \n",
    "            \n",
    "        if (num_data_points > 0):\n",
    "            dictionary['mean_flight_time'] = mean_flight_time/num_data_points\n",
    "            dictionary['mean_latency_time'] = mean_latency_time/num_data_points\n",
    "            dictionary['mean_hold_time'] = mean_hold_time/num_data_points\n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateLinearRegressionModels():\n",
    "    def __init__(self):\n",
    "        self.processed_data = PreprocessedData()\n",
    "        self.patient_data = self.processed_data.get_patient_data()\n",
    "        self.tappy_data = self.processed_data.get_tappy_data()\n",
    "    \n",
    "    def create_single_regressions(self):\n",
    "    # Create all possible combinations of single regressions\n",
    "    # Find the most accurate of all of them using mean squared error\n",
    "        x1 = []\n",
    "        x2 = []\n",
    "        x3 = []\n",
    "        y1= []\n",
    "        y2 = []\n",
    "        y3 = []\n",
    "        \n",
    "        for i in self.tappy_data:\n",
    "            if i[0] in self.patient_data and 'mean_flight_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y1.append(1)\n",
    "                else:\n",
    "                    y1.append(0)\n",
    "                \n",
    "                x1.append(self.tappy_data[i]['mean_flight_time'])\n",
    "            \n",
    "            if i[0] in self.patient_data and 'mean_latency_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y2.append(1)\n",
    "                else:\n",
    "                    y2.append(0)\n",
    "                x2.append(self.tappy_data[i]['mean_latency_time'])\n",
    "            \n",
    "            if i[0] in self.patient_data and 'mean_hold_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y3.append(1)\n",
    "                else:\n",
    "                    y3.append(0)\n",
    "                x3.append(self.tappy_data[i]['mean_hold_time'])\n",
    "        self.perform_singular_linear_regression([x1,y1])\n",
    "        self.perform_singular_linear_regression([x2,y2])\n",
    "        self.perform_singular_linear_regression([x3,y3])\n",
    "    \n",
    "    def perform_singular_linear_regression(self, input_output):\n",
    "        \n",
    "        x = numpy.array(input_output[0]).reshape((-1,1))\n",
    "        y = numpy.array(input_output[1])\n",
    "        model = LinearRegression().fit(x,y)\n",
    "        print(model.score(x,y))\n",
    "        return model\n",
    "    \n",
    "    def perform_multiple_linear_regression(self, input_output):\n",
    "        # Perform multilple linearn regressions\n",
    "        # Given a 2D arrat x and an output y (using 30% traingin data)\n",
    "        x = numpy.array(input_output[0])\n",
    "        y = numpy.array(input_output[1])\n",
    "        model = LinearRegression().fit(x,y)\n",
    "        print(model.score(x,y))\n",
    "        return model\n",
    "       \n",
    "    def find_coefficient_of_determination(self, model, x, y):\n",
    "        # Find the mean squared error of a model given model attributes\n",
    "        # assume 30% testing data\n",
    "        print(model.score(x,y))\n",
    "        return model.score(x,y)\n",
    "    \n",
    "    def create_multiple_regressions(self):\n",
    "        # Create all possible multiple regression models\n",
    "        # Used mean squared error to find the most effective\n",
    "        x1_x2 = []\n",
    "        x2_x3 = []\n",
    "        x1_x3 = []\n",
    "        x1_x2_x3 = []\n",
    "\n",
    "        y1_y2 = []\n",
    "        y2_y3 = []\n",
    "        y1_y3 = []\n",
    "        y1_y2_y3 = []\n",
    "\n",
    "    \n",
    "        for i in self.tappy_data:\n",
    "            if i[0] in self.patient_data and 'mean_flight_time' in self.tappy_data[i] and 'mean_latency_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y1_y2.append(1)\n",
    "                else:\n",
    "                    y1_y2.append(0)\n",
    "                \n",
    "                x1_x2.append([self.tappy_data[i]['mean_flight_time'],self.tappy_data[i]['mean_latency_time']])\n",
    "            \n",
    "            \n",
    "            if i[0] in self.patient_data and 'mean_flight_time' in self.tappy_data[i] and 'mean_hold_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y2_y3.append(1)\n",
    "                else:\n",
    "                    y2_y3.append(0)\n",
    "                x2_x3.append([self.tappy_data[i]['mean_flight_time'],self.tappy_data[i]['mean_hold_time']])\n",
    "        \n",
    "            if i[0] in self.patient_data and 'mean_latency_time' in self.tappy_data[i] and 'mean_hold_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y1_y3.append(1)\n",
    "                else:\n",
    "                    y1_y3.append(0)\n",
    "                x1_x3.append([self.tappy_data[i]['mean_latency_time'],self.tappy_data[i]['mean_hold_time']])\n",
    "            \n",
    "            if i[0] in self.patient_data and 'mean_latency_time' in self.tappy_data[i] and 'mean_hold_time' in self.tappy_data[i] and 'mean_flight_time' in self.tappy_data[i]: \n",
    "                if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                    y1_y2_y3.append(1)\n",
    "                else:\n",
    "                    y1_y2_y3.append(0)\n",
    "                x1_x2_x3.append([self.tappy_data[i]['mean_latency_time'],self.tappy_data[i]['mean_hold_time'], self.tappy_data[i]['mean_flight_time']])\n",
    "                \n",
    "                \n",
    "                \n",
    "        self.perform_multiple_linear_regression([x1_x2,y1_y2])\n",
    "        self.perform_multiple_linear_regression([x2_x3,y2_y3])\n",
    "        self.perform_multiple_linear_regression([x1_x3,y1_y3])\n",
    "        self.perform_multiple_linear_regression([x1_x2_x3,y1_y2_y3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class CreateKerasClassifier():\n",
    "        def __init__(self):\n",
    "            self.processed_data = PreprocessedData()\n",
    "            self.patient_data = self.processed_data.get_patient_data()\n",
    "            self.tappy_data = self.processed_data.get_tappy_data()\n",
    "\n",
    "\n",
    "        def model_with_deep_learning(self):\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "            x1_x2_x3 = []\n",
    "            y1_y2_y3 = []\n",
    "            for i in self.tappy_data:\n",
    "                if i[0] in self.patient_data and 'mean_latency_time' in self.tappy_data[i] and 'mean_hold_time' in self.tappy_data[i] and 'mean_flight_time' in self.tappy_data[i]: \n",
    "                    if self.patient_data[i[0]]['Parkinsons:'] == 'True':\n",
    "                        y1_y2_y3.append(1)\n",
    "                    else:\n",
    "                        y1_y2_y3.append(0)\n",
    "                    x1_x2_x3.append([self.tappy_data[i]['mean_latency_time'],self.tappy_data[i]['mean_hold_time'], self.tappy_data[i]['mean_flight_time']])\n",
    "\n",
    "            X = numpy.array(x1_x2_x3)\n",
    "            Y = numpy.array(y1_y2_y3)\n",
    "\n",
    " \n",
    "            #Model is defined to active when called by Keras\n",
    "            def create_model():\n",
    "                # create model\n",
    "                keras_model = Sequential()\n",
    "                \n",
    "                #input_dim is set to the number of input params in this case 3\n",
    "                # Using normal  kernel init and relu activation\n",
    "                keras_model.add(Dense(8, input_dim = 3, kernel_initializer='normal', activation='relu'))\n",
    "                keras_model.add(Dense(4, input_dim = 3, kernel_initializer='normal', activation='relu'))\n",
    "                keras_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                #Configure the learning rate of the model\n",
    "                adam = Adam(lr = 0.01)\n",
    "                keras_model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "\n",
    "                return keras_model\n",
    "                \n",
    "\n",
    "            \n",
    "            model = create_model()\n",
    "            \n",
    "            #Get summarization of the model\n",
    "            model_summary = model.summary()\n",
    "            \n",
    "            seed= 6\n",
    "            \n",
    "            #Generate random seed\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            \n",
    "            #Create KerasClassifier \n",
    "            model = KerasClassifier(build_fn= create_model, verbose=0)\n",
    "\n",
    "            #Define grid search parameter\n",
    "            batch_size= [10,20,40]\n",
    "\n",
    "            epochs = [10,50,100]\n",
    "\n",
    "            #need a dictionary of the grid search\n",
    "\n",
    "            param_grid= dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "            #build and fitGridSearch\n",
    "\n",
    "            grid= GridSearchCV(estimator = model, param_grid= param_grid, \n",
    "                              cv= KFold(random_state=seed), verbose = 10)\n",
    "            \n",
    "            scaler=StandardScaler().fit(X)\n",
    "\n",
    "            X_standardized= scaler.transform(X)\n",
    "\n",
    "            grid_results= grid.fit(X_standardized, Y)\n",
    "\n",
    "\n",
    "            #Summarize results of the network\n",
    "            \n",
    "            print(grid_results.best_score_)\n",
    "            print(grid_results.best_params_)\n",
    "\n",
    "            return [grid_results.best_score_,grid_results.best_params_]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravinsivakumar/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:426: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aravinsivakumar/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "[CV]  batch_size=10, epochs=10, score=0.7526881694793701, total=   3.0s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=10, score=0.7903226017951965, total=   2.5s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=10, score=0.7526881694793701, total=   2.7s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=50, score=0.7526881694793701, total=   5.1s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   13.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=50, score=0.7903226017951965, total=   5.5s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   18.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=50, score=0.7526881694793701, total=   6.1s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   25.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=100, score=0.7526881694793701, total=   9.1s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   34.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=100, score=0.7903226017951965, total=   9.1s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   43.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=10, epochs=100, score=0.7526881694793701, total=   9.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   52.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=20, epochs=10, score=0.7526881694793701, total=   2.6s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV]  batch_size=20, epochs=10, score=0.7903226017951965, total=   2.8s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV]  batch_size=20, epochs=10, score=0.7526881694793701, total=   3.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV]  batch_size=20, epochs=50, score=0.7526881694793701, total=   4.5s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV]  batch_size=20, epochs=50, score=0.7903226017951965, total=   4.8s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV]  batch_size=20, epochs=50, score=0.7526881694793701, total=   4.7s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV]  batch_size=20, epochs=100, score=0.7526881694793701, total=   6.8s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV]  batch_size=20, epochs=100, score=0.7903226017951965, total=   7.0s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV]  batch_size=20, epochs=100, score=0.7526881694793701, total=   6.8s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV]  batch_size=40, epochs=10, score=0.7526881694793701, total=   3.5s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV]  batch_size=40, epochs=10, score=0.7903226017951965, total=   3.4s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV]  batch_size=40, epochs=10, score=0.7526881694793701, total=   3.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV]  batch_size=40, epochs=50, score=0.7526881694793701, total=   5.1s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV]  batch_size=40, epochs=50, score=0.7903226017951965, total=   4.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV]  batch_size=40, epochs=50, score=0.7526881694793701, total=   5.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV]  batch_size=40, epochs=100, score=0.7526881694793701, total=   7.0s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV]  batch_size=40, epochs=100, score=0.7903226017951965, total=   6.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV]  batch_size=40, epochs=100, score=0.7526881694793701, total=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7652329802513123, using {'batch_size': 10, 'epochs': 10}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 10, 'epochs': 10}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 10, 'epochs': 50}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 10, 'epochs': 100}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 20, 'epochs': 10}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 20, 'epochs': 50}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 20, 'epochs': 100}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 40, 'epochs': 10}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 40, 'epochs': 50}\n",
      "0.7652329802513123 0.01774104153108467 {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "models = CreateKerasClassifier().model_with_deep_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
